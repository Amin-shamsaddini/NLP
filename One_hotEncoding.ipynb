{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrftYFkwuOssdS5jKJr6Ln",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amin-shamsaddini/NLP/blob/main/One_hotEncoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##One-hot Encoding\n",
        "In Numpy\n",
        "\n",
        "Step1. Convert Text to lower case\n",
        "\n",
        "Step2. Tokenize the text\n",
        "\n",
        "Step3. Get unique words\n",
        "\n",
        "Step4. Sort the word list\n",
        "\n",
        "Step5. Get the integer/position of the words\n",
        "\n",
        "Step6. create a vector of each word by marking its position as 1 and rest as 0\n",
        "\n",
        "Step7. create a matrix of the found vectors."
      ],
      "metadata": {
        "id": "8JwWPtiXbUdu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RL7-5sb-06ly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6345fc05-a495-4094-8674-41caa257bcea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "values:  ['i', 'learn', 'nlp', 'should']\n",
            "\n",
            "integer encoded:  [3, 0, 1, 2]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "docs = \"Should I learn NLP\"\n",
        "doc = docs.lower().split()\n",
        "doc1 = set(doc)\n",
        "doc1 = sorted(doc1)\n",
        "print (\"\\nvalues: \", doc1)\n",
        "\n",
        "integer_encoded = []\n",
        "\n",
        "for i in doc:\n",
        "  v=int(np.where(np.array(doc1)==  i)[0][0])\n",
        "  integer_encoded.append(v)\n",
        "\n",
        "print (\"\\ninteger encoded: \",integer_encoded)\n",
        "\n",
        "\n",
        "def get_vec(len_doc,word):\n",
        "    empty_vector = [0] * len_doc\n",
        "    vect = 0\n",
        "    find = np.where( np.array(doc1) == word)[0][0]\n",
        "    empty_vector[find] = 1\n",
        "    return empty_vector\n",
        "\n",
        "def get_matrix(doc1):\n",
        "    mat = []\n",
        "    len_doc = len(doc1)\n",
        "    for i in docs:\n",
        "        vec = get_vec(len_doc,i)\n",
        "        mat.append(vec)\n",
        "\n",
        "    return np.asarray(mat)\n",
        "\n",
        "print (\"\\nMATRIX:\")\n",
        "print (get_matrix(doc1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##In Sklearn\n",
        "Step1. Convert the text to Lower Case  \n",
        "Step2. Word Tokenize   \n",
        "Step3. Get its integer value i.e the position by using LabelEncoder()  \n",
        "Step4. Get one hot encoding of the word by referring to the label encoded values using OneHotEncoder()"
      ],
      "metadata": {
        "id": "jzKDBYUMLq9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "doc1 = \"Should I learn NLP\".lower()\n",
        "doc2 = \"You must learn NLP\".lower()\n",
        "doc1 = doc1.split()\n",
        "doc2 = doc2.split()\n",
        "doc1_array = array(doc1)\n",
        "doc2_array = array(doc2)\n",
        "doc3 = doc1+doc2\n",
        "# doc3 = set(doc3)\n",
        "data = list(doc3)\n",
        "\n",
        "values = array(data)\n",
        "print(values)\n",
        "\n",
        "# integer encode\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "print(integer_encoded)\n",
        "\n",
        "\n",
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1 )\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "print(onehot_encoded)\n",
        "\n",
        "\n",
        "###\n",
        "print(\"------------------------\")\n",
        "val = values.reshape(-1,1)\n",
        "one_hot = onehot_encoder.fit_transform(val)\n",
        "print(one_hot)\n",
        "\n",
        "\n",
        "\n",
        "# invert first example\n",
        "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
        "print(inverted)"
      ],
      "metadata": {
        "id": "C0uWOZNaL13g",
        "outputId": "2a296c31-869a-43ea-8a29-255d8f38881b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['should' 'i' 'learn' 'nlp' 'you' 'must' 'learn' 'nlp']\n",
            "[4 0 1 3 5 2 1 3]\n",
            "[[0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]]\n",
            "------------------------\n",
            "[[0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]]\n",
            "['should']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##In Keras\n",
        "Step1. Convert the text to Lower Case  \n",
        "Step2. Word Tokenize  \n",
        "Step3. Get its integer value i.e the position by using LabelEncoder()  \n",
        "Step4. Get one hot encoding of the word by referring to the label encoded  values by using to_categorical()"
      ],
      "metadata": {
        "id": "zeSiRFPWUfSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "doc = \"Should I learn NLP\".lower().split()\n"
      ],
      "metadata": {
        "id": "zzieQ1XfUtBE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}